{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe4efbd",
   "metadata": {},
   "source": [
    "# The Sidekick\n",
    "\n",
    "It's time to introduce:\n",
    "\n",
    "1. Structured Outputs\n",
    "2. A multi-agent flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5c101",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "from langchain_core import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "import uuid\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ab362",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f14b7",
   "metadata": {},
   "source": [
    "### For structured outputs, we define a Pydantic object for the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d653a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For structured outputs, we define a Pydantic object for the Schema\n",
    "\n",
    "class EvaluatorOutput(BaseModel):\n",
    "    feedback: str = Field(description = \"Feedback on the assistant's response\")\n",
    "    success_criteria_met: bool = Field(description = \"Whether the success criteria have been met\")\n",
    "    user_input_needed: bool = Field(description = \"True if more input is needed from the user, or clarifications, or the assistant is stuck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95c265",
   "metadata": {},
   "source": [
    "### And for the State, we'll use TypedDict again\n",
    "\n",
    "But now we have some real information to maintain!\n",
    "\n",
    "The messages uses the reducer. The others are simply values that we overwrite with any state change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The state\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[ANY], add_messages]\n",
    "    success_criteria: str\n",
    "    feedback_on_work: Optional[str]\n",
    "    success_criteria_met: bool\n",
    "    user_input_needed: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our async Playwright tools\n",
    "# If you get a NotImplementedError here or later, see the Heads Up at the top of the 3_lab3 notebook\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio_apply()\n",
    "async_browser = create_async_playwright_browser(headless=False)  # headful mode\n",
    "toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fa7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLMs\n",
    "\n",
    "worker_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "worker_llm_with_tools = worker_llm.bind_tools(tools)\n",
    "\n",
    "evaluator_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "evaluator_llm_with_output = evaluator_llm.with_structured_output(EvaluatorOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The worker node\n",
    "\n",
    "def worker(state: State) -> Dict[str, Any]:\n",
    "    system_message = f\"\"\"You are a helpful assistant that can use tools to complete tasks.\n",
    "You keep working on a task until either you have a question or clarification for the user, or the success criteria is met.\n",
    "This is the success criteria:\n",
    "{state['success_criteria']}\n",
    "You should reply either with a question for the user about this assignment, or with your final response.\n",
    "If you have a question for the user, you need to reply by clearly stating your question. An example might be:\n",
    "\n",
    "Question: please clarify whether you want a summary or a detailed answer\n",
    "\n",
    "If you've finished, reply with the final answer, and don't ask a question; simply reply with the answer.\n",
    "\"\"\"\n",
    "\n",
    "    if state.get(\"feedback_on_work\"):\n",
    "        system_message += f\"\"\"\n",
    "Previously you thought you completed the assignment, but your reply was rejected because the success criteria was not met.\n",
    "Here is the feedback on why this was rejeceted:\n",
    "{state['feedback_on_work']}\n",
    "with this feedback, please continue the assignment, ensuring that you meet the success criteria or have a question for the user.\"\"\"\n",
    "\n",
    "    # Add in the system message\n",
    "\n",
    "    found_system_message = False\n",
    "    messages = state[\"messages\"]\n",
    "    for message in messages:\n",
    "        if isinstance(message, SystemMessage):\n",
    "            message.content = system_message\n",
    "            found_system_message = True\n",
    "\n",
    "    if not found_system_message:\n",
    "        messages = [SystemMessage(content=system_message)] + messages\n",
    "\n",
    "    # Invoke the LLM with tools\n",
    "    response = worker_llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
